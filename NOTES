TENSOR HEAVEN - Tenh (pronounced "tench", similar to hyperbolic tangent tanh)

NOTES
- all library code is in tenh/
  * ideally there will be few/no cpp files
- only the root directory (the directory containing tenh/) should be included, in the same manner as Eigen.
- all test code is in tensorhell/ -- there are currectly ad-hoc tests/prototype code (e.g. eigen_interop_prototype.cpp
  and contraction_prototype.cpp), but the "real" tests are in the standard/ subdirectory.  the CMakeLists.txt file
  in the tensorhell/ subdirectory will build all of these.  the executable name for the "real" tests is "test".
- the "actual" tensor lib prototype code is in test/contraction_prototype.cpp
- some prototype code for strongly-typed vectors (which distinguish prime/dual spaces and "named" spaces)
  is in tensorhell/strongly_typed_vector_prototype.cpp

current goals:
- more frontends for Eigen functionality -- LDLT, QR, linear solve, etc
- strong typing for vectors -- named vector spaces (including "Generic") and prime/dual distinction (including self-dual)
  * default values should be "Generic" vector space ID and self-dual
  * canonical isomorphism for tensor2 -> vector will need to take into account basis
  * canonical isomorphism for vector -> scalar will need to take into account basis (a 1-dimensional vector space always has a
    canonical "unit" basis element which is the real number 1 (?))
  * template <typename Scalar, Uint32 DIM, typename VectorSpaceId, typename BasisId> struct Vector_t (NO default values)
  * VectorSpaceId should have the Dual space type (can specify self-dual here), and a static type_as_string method
  * BasisId should just be a "name" (a type, e.g. struct DiagonalizedBasis)
  * There should be a generic vector space type -- EuclideanSpace (?)
  * There should be a generic basis type -- StandardBasis (?) -- where the inner product is the identity
- column/row/block extraction/addressing
  * something like a(i|c(2)), where i is a TypedIndex_t<Vector,'i'> and c is an Index_t<Vector>
  * will need to somehow distinguish the type of i|c(2) from something like i|j, because a(i|c(2)) is an
    expression template with a particular fixed index plugged in.
- implement inner products and so forth using Tensor_i.
  this regularizes the implementation and relates to metrics/inner products
  * contractions will "request" the pairing, and if the type exists, the contraction works
    this would allow more flexibility in contractions (e.g. contracting a vector space V with itself via an inner product).
- isometric embedding for various types (e.g. Tensor2Symmetric_t, Tensor2Antisymmetric_t, so that SVD and other
  stuff can be used on them meaningfully, as the SVD and so forth depends on the metric of the relevant space,
  and the way Tensor2Symmetric_t is implemented does not use an isometric representation).
  * the isometric embedding should be the square root of the inner product.

future goals:
- a rigorous test suite, using Lvd test code -- it can handle everything up through seg faults -- and negative compile
  tests implemented at the build level, so that particular intentional compile errors can be verified to work.
- standard in-line linear algebra notation
  * for example, if A is a matrix and v is a vector, "A*v" should be equivalent to "A(i|j)*v(j)", but obviously
    without the need to use an indexed expression.
- optimize evaluation algorithm (ordering operations to do the minimal amount of computation)
- vectorizing as many operations as possible (in cooperation with loop-unrolling?)
- template specializations for particular tensor contractions for speed (using mathematical special cases)
  * for example, an antisymmetric 3x3 2-tensor contracted with a 3-vector is just a cross product
  * a diagonal 2-tensor contracted with a vector is just component-wise scaling
- in strongly typed vector template identifier types, require certain tags (e.g. static member constants)
  in the template parameters -- vector space identifier, vector space basis, etc.
- certain linear algebraic expressions simplify greatly when expressed in a particular basis,
  so having a formal mechanism to work with explicit bases may clarify and simplify some calculations

random TODOs:
- implement [anti]symmetric contiguous_index_to_rowcol_index as a lookup table for speed.
- allow use of same indices across different terms (distinguishing multiplication and addition)
- see if it's possible to do strong range check guarantees for indices (Index_t) -- this would probably
  require a "for each" construct which would best be accomplished with lambda expressions
- rename source files to use capitalized names (e.g. NaturalPairing.hpp) (?)
- move "private" utility functions/metafunctions into the "Tenh::NonPublic" namespace so that they're not in the
  "Tenh" namespace, for at least a little bit of non-public interface hiding.
- make a nonpublic directory and put all NonPublic code in there (and actually put appropriate stuff in NonPublic namespace)
- allow 0-dimensional vector spaces (otherwise certain induced types (e.g. antisymmetric 2-tensors) will cause static asserts)
- make a wrapper for creating analogous Eigen::Matrix types which handles the retarded issue with
  Eigen::Matrix<Scalar,N,1,RowMajor> not working because it's a column vector (even though the memory would
  be layed out identically).
- use -Wno-tautological-compare for clang builds
- is it possible to specify the default value for Derived directly?
- make various tensor types check the IS_XYZ values for their template parameters
- see if some sort of static_cast can be used to detect if a type inherts a class, and use this to replace
  IS_EXPRESSION_TEMPLATE, IS_TENSOR2_T, etc.  Or failing that, use some template metafunction for this.
- in relaxing the C++-driven type checking in preference to static-assert-driven type checking, could make all
  indices used in indexed expressions "weakly typed", except for bundled indices (e.g. the index p in
  t(i|j).bundle(i|j,p) -- it is necessary to know the type of p for this to be a well-defined bundle).  all
  other index types can be inferred from their use in the expression.
- decide on template metaprogramming naming convention.  something along the lines of
  * Blah_t<...> for types that actually implement stuff and have significant runtime code (is there
    something better than _t ?)
  * Blah_c<...> for the conceptual layer
  * Blah_i<...> for the templatized interface layer (this is somewhere between _c and _i)
  * Blah_m<...> for meta-programmingy things like type lists and related metafunctions
  * Blah_f<...> for meta-functions which "return" a type T
- add "operator std::string ()" to TypeStringOf_t (?), so that "TypeStringOf_t<Foo>()" can be used
- rename List_t::body() to List_t::body_list(), since the body list type is BodyList

features necessary for version 0.5:
x euclidean embedding (using short-term zero-dimensional hack (?))
x eval (for 2-tensors)
x basis specification (e.g. in diagonalization/SVD, and the orthonormal matrix could/should be called "basis vectors")
- provide a way to "name" the basis for diagonalization/SVD/etc
x stub-out: noalias (?) for situations like a(i) = a(i) + b(i), but also to avoid the runtime check of aliasing, so the human
  can specify no-alias in a situation like a(i) = b(i) + c(i).
- additional eigen interop:
  * 2-tensor inverse            - done and tested
  * LDLT and LDLT solve
  * non-self-adjoint eigensolve
  * LU

basis considerations for strongly typed vector edition:
- several choices for bases on induced tensor products exist
  * "normalized" where square roots of multiplicities occur in both vector space and dual
    which is a "safe" compromise in the sense that it is uniform between vector space and dual
    but has the lowest component-to-actual-memory-location correspondence
  * "dual of induced basis", where the dual space incorporates the multiplicities
    which has an intermediate level of component-to-actual-memory-location correspondence
    but natural pairings never involve multiplicities
  * "induced of dual basis", where the dual space doesn't incorporate multiplicities
    which (probably) has the highest component-to-actual-memory-location correspondence
    but natural pairings involve the multiplicities
- the choice of basis will depend on the particular problem being addressed
  * some problems are contraction heavy, in which case "dual of induced basis" could be a good choice
  * some problems are split/bundle heavy, in which case the "induced of dual basis" could be a good choice

implemented features/items:
x operator overloads for expression templates
x trace-type expression templates (where a tensor is contracted with itself, a case which is distinct from * style expression templates)
x prohibiting 3+ summed index expressions
x assignment expression templates
x check assignment for aliasing
x symmetric 2-tensors
x antisymmetric 2-tensors
x custom natural pairing (for non-isometric parameterizations)
x scalar multiplication/division in expression templates
x unary negation in expression templates
x printing expression templates
x down-casting tensors (extracting symmetries out of "broken apart" indexed tensor expressions);
  "bundling" multi-indices into a more-specific "total" index type
x up-casting tensors (breaking symmetries indexed tensor expressions);
  "splitting" a tensor "total" index into a less-specific multi-index
x diagonal 2-tensors
x SVD on 2-tensors, using Eigen
x eigen-decomposition of symmetric 2-tensors, using Eigen
x Eigen interop for using Tensor2_t as Eigen::Map (no memory copy necessary)
x functions for converting Tensor2Antisymmetric_t and Tensor2Symmetric_t to Eigen::Matrix types
x eval method for expression templates (to avoid aliasing problem when assigning)
x no_alias method for avoiding the run-time check against aliased expression template assignments
x Euclidean embeddings for vector and tensor types for when an inner-product-compatible representation is needed.
x Basis identifier for each vector space, giving an additional feature to distinguish vector types with,
  for added correctness, which is particularly useful for the Euclidean embedding stuff.

---------------------------

different multi-indexing schemes
- "split"                 : if t is Tensor2<Tensor2Sym<V>,Tensor2Sym<V> >, then t(P,Q).split(P,i,j),split(Q,k,l)
                            is converse to bundle, implementation would be similar.
- "multi-index"           : if s is Tensor2<Tensor5,V>, then s(i,j,k,l,m,T) would be s(multiindex(i,j,k,l,m),T)
                            implementation may be difficult if there are nested multi-indices
- "streaming multi-index" : s/i/j/k/l/m/T or s^i^j^k^l^m^T -- need intermediate "streaming" type
                            left to right, breaking types until there is a match, implementation is probably
                            recursive and relatively easy.  "breaking tensor type boxes apart recursively"
- "barred multi-index"    : s(i|j|k|l|m|T)

handling more general symmetries
- each "linear" symmetry is an inclusion of a linear subspace into a more general type
- any type hierarchy can be encoded this way -- e.g. including Tensor2Simple into Tensor2
- "split" would be used to "use" the inclusions, going to more general types.
  a split is a more specific type of linear inclusion, where each component of the split corresponds
  to exactly one component of the space that is split.
- "bundle" would be used to "reassert" the symmetries, if you know that the expression has that symmetry.
  would this work for simple tensors?  there would be a nontrivial calculation to assign to a simple tensor.

categorical/conceptual design ideas
- use _c for "category" or "conceptual"
- Field_c<Id>
  * Field_c<Real_c>
  * Field_c<Complex_c>
  * Field_c<F2_c>
  * etc (quaternions could be used, as a skew-field, and maybe SkewField_c<Id> could be a thing
    this should be able to check the validity of a Scalar type (e.g. float, double, int, bool)
    for a field (so Real_c could use float or double, but not int, whereas F2_c could use int but
    not float or double).
  * Module_c, Ring_c (?)

- VectorSpace_c<Field,DIM,Id>
  * Id is just a "name" for the particular type (so that vector spaces can be distinguished
    by more than just their field and dimension), e.g. struct Device3Space { }; or
    struct Screen2Space { };
- Basis_c<VS,Id>
  * A strongly typed "tag" to denote a basis

- Dual_c<X>
  * X could be a VectorSpace_c or a Basis_c
- TensorProduct_c<X1,X2,...,Xn>
  * Xi could be a VectorSpace_c or a Basis_c
  * maybe support taking tensor products of BasedVectorSpace_c ?
  * if it is "overloaded" like this, then maybe use TensorProductOf_c<X1,...,Xn> as a template
    typedef (i.e. used via the typedef TensorProductOf_c<...>::T, which returns a
    TensorProduct_c<V1,...,Vn> or TensorProduct_c<Basis1,...,Basisn> or
    BasedTensorProduct_c<BVS1,...,BVSn>)
  * if it is overloaded, it would probably make sense to make separate templates
    TensorProductOfVectorSpaces_c, TensorProductOfBases_c, etc.
- TensorPower_c<X,ORDER>
  * X could be a VectorSpace_c or a Basis_c
- ExteriorPower_c<X,ORDER>
  * X could be a VectorSpace_c or a Basis_c
- SymmetricPower_c<X,ORDER>
  * X could be a VectorSpace_c or a Basis_c
- TODO: Young Tableaux
- Scalar2TensorProduct_c<X>
  * The 1-dimensional space of all scaling endomorphisms of X
  * should have a conversion to TensorProduct_c<X,Dual_c<X> >

- BasedVectorSpace_c<VectorSpace,Basis>
  * is really just a way to specify a vector space with a choice of basis
- BasedTensorProduct_c<TensorProduct,Basis>
  * a choice of tensor product and basis for each factor
  * e.g. BasedTensorProduct_c<TensorProduct_c<V1,V2>,TensorProduct_c<Basis1,Basis2> >
- BasedTensorPower_c<TensorPower,Basis>
  * a choice of tensor power and basis for said power
- BasedExteriorPower_c<ExteriorPower,Basis>
  * a choice of exterior power and basis for said power
- BasedSymmetricPower_c<SymmetricPower,Basis>
  * a choice of symmetric power and basis for said power
- TODO: Based Young Tableaux
- ScalarBased2TensorProduct<X,Basis>
  * is this necessary?
  * should have a conversion to DiagonalBased2TensorProduct_c.
- DiagonalBased2TensorProduct_c<VS1,VS2,Basis1,Basis2>
  * guarantees that the based representation of the tensors in this space have the form
  \lambda^{i}_{j}, where \lambda^{i}_{j} = 0 if i != j, and i and j are are indices for
  (VS1,Basis1) and (VS2,Basis2) respectively.
- Would it make sense to have a "diagonal" based tensor product of arbitrary order?  where
  the indices i and j become multiindices?
- LowerTriangularBased2TensorProduct_c<VS1,VS2,Basis1,Basis2>
  * similar to Diagonal2BasedTensorProduct_c, only with assuming that the matrix is lower triangular
- More along the same lines, such as StrictlyLowerTriangularBased2TensorProduct_c,
  UpperTriangularBased2TensorProduct_c, etc.

While Dual_c<TensorPower_c<Basis_c<V,Id>,N> > is the same as TensorPower_c<Dual_c<Basis_c<V,Id> >,N>,
Dual_c<ExteriorPower_c<Basis_c<V,Id>,N> > is different than ExteriorPower_c<Dual_c<Basis_c<V,Id> >,N>
due to a discrepancy in the multiplities (the pairing is off by a factor of N!).

- Vector_i<Scalar,VectorSpaceAndBasis>
  * is the compile-time interface for a type that will be an instance of a vector
  * this is where the expression-template-generating code goes (via operator())
- Tensor_i<Scalar,TensorProductAndBasis>
  * is the compile-time interface for a type that will be an instance of a tensor
  * this is where the expression-template-generating code goes (via operator())

- Vector_t<Scalar,DIM,BasedVectorSpace = BasedVectorSpace_c<EuclideanInnerProductSpace<Scalar,DIM>,StandardBasis> >
  * actual implementation of a strongly typed vector (whose default values make it weakly typed)
- Tensor_t<Scalar,BasedTensorProduct>
  * actual implementation of a strongly typed tensor (no default values, as that wouldn't make sense)

Notes for conceptual layer and refactor
- In order to incorporate the order-of-operations and diagonal 2-tensor contraction optimizations,
  the operator overloads which generate expression templates should do the expression template AST
  optimization (e.g. if the expression is a(i)*d(i|j)*b(j) and d is diagonal, then this should turn
  into an expression template that sums a(k)*d(k|k)*b(k) with the single index k).  In the case where
  a change of order of operations would produce an optimization, the expression template AST tree
  should be modified here -- this affects the return type of each operator overload.
- Should the index-notated expression templates be done at the conceptual level?  The optimization
  and type checking could be done here in isolation from the actual computation -- effectively
  the conceptual level will produce an "optimized AST" expression template.  While the indexed
  expressions should all be tensorial in nature, some of the optimizations depend on the chosen
  basis (e.g. the diagonal based 2-tensor product one), so this should be done at the
  based-vector-space and based-tensor-product level.
- Provide way to specify/override natural pairing on any given space -- use Alt convention by
  default (this gives certain simplifications), but for example the det convention would make
  use of finite-characteristic fields possible.
- Indexing scheme for wedges and symmetric products consists of sorting the indices of a multi-index.
  For Young tableaux, this would generalize to imposing sorting constraints on various subsets of
  indices (based on the rows (alternating) and columns (symmetric)).  Negative signs are accumulated
  for swaps in rows, and zero is returned for repetitions in the rows.
- Grey (gray?) coding scheme would be desired for generating non-symmetric multi-indices for
  when iterating through components for e.g. the bundle operation.
- Think about difference between BasedTensorProduct (which may have basis elements which are non-simple,
  thereby complicating the component access for the split operation) and TensorProductOfBasedVectorSpaces
  (whose basis elements are all simple, and therefore give a simple operation for the split operation).
  It might make sense to prohibit non-simple tensor product bases, opting for explicit embeddings
  instead (which is [probably] computationally equivalent and better yet, makes it more clear that
  extra computation is necessary in the tensor expressions themselves).  In this case, BasedTensorProduct
  might be downgraded to BasedVectorSpace.  Or probably better, BasedTensorProduct would be implemented
  using the Vector_i interface, and not the EmbeddableAsTensor_i or Tensor_i interfaces.
- Idea for handling the split operation -- don't bother with multi-indices for any sort of tensor
  power with symmetry, and only do multi-indices for TensorProductOfBasedVectorSpaces_c.  Then use
  explicit embeddings (which are easy to explicitly specify via C++ code in indexed expressions, and
  they would almost always use diagonal 2-tensors (NOTE: this part about "diagonal" is not true, but
  you would almost always have a sparse matrix)) to embed the symmetric thing in the non-symmetric
  space, in which the contractions are actually done.  This way, the choice of "projection" embedding
  or "scalar multiple of projection" can be made clearly and explicitly, instead of through some weird
  choice of template type.  Another advantage to this approach is that "smaller" splits can be done --
  e.g. splitting "S^4 V" into "S^2 V \otimes S^2 V" or into "V \otimes S^3 V", and this might be a
  crucial feature, as it really enriches the type system without adding too much library-template-driven
  code (the embeddings would be neatly packaged bits of code that could be user-specified also).
- Possible idea for efficient contraction of tensors having different symmetries -- express their
  contraction as a linear map (a 2-tensor), then contract this with the outer product of the operands.
- Use ImplementationOf_t<ConceptualType> to instantiate vectors and tensors?  This would be something like
    ImplementationOf_t<R4> x; // a 4-vector
  or
    ImplementationOf_t<BasedTensorPower_c<R3,2> > y; // a 2-tensor over R^3.
  or
    ImplementationOf_t<BasedTensorPower_c<R3,0> > r; // a scalar (or convertible to one)
  or
    ImplementationOf_t<BasedTensorPower_c<R4,1> > z; // same as x.
- Changing over to AbstractIndex_c<char SYMBOL> should be done -- the "bundle" operation would then
  need to specify the bundling type explicitly (which is probably a good thing).  This may simplify
  a bunch of code, and ease the honey-bucket approach to compile-time checking.
- Could make Vector_i not be an indexable object, but rather require usage of tensors to provide this.
  This would probably collapse some library code, but could make instantiating a vector more annoying
  for the user.
- ImplementationOf_t<WhateverSymmetricTensorType> should not inherit Tensor_i, but rather Vector_i,
  because you shouldn't be able to multi-index them directly -- use split instead.  On the other hand,
  this would make certain operations (like accessing a particular component of a symmetric tensor) non-
  intuitive and clunky.  Actually, instead of Vector_i, maybe make a third interface called something
  like EmbeddableAsTensor_i, that is somewhere between Vector_i and Tensor_i, and where multi-indexing
  (to create expression templates) calls split.
- TODO: reverse order of template arguments in ImplementationOf_t (put Scalar last)
- TODO: refactor all the AbstractIndex/DimIndex/Factor juggling to use some standard form, like
  (AbstractIndex,Factor) pairs, from which the AbstractIndex, Factor, or DimIndex values can be
  extracted.  This will clean up tons of shitty metaprogram code.
  Or maybe use TypedIndex_t after all (it would inherit DimIndex_t and contain the factor info)
- Conceptual interface checkers: something like
  template <typename T>
  struct Check_TensorProductOfVectorSpaces_c
  {
      typedef typename T::FactorTypeList FactorTypeList;
      static Uint32 const ORDER = T::ORDER;
      // etc

      static bool const V = true; // used for instantiating/using this check in an static assert

      enum 
      { 
          STATIC_ASSERT_IN_ENUM(Check_VectorSpace_c<T>::V, MUST_BE_VECTOR_SPACE)
          STATIC_ASSERT_IN_ENUM(EachTypeIsVectorSpace_c<FactorTypeList>, MUST_BE_TYPELIST_OF_VECTOR_SPACES) 
      };
  };
  Hopefully this would cause an error if any of the members/typedefs were missing (TODO: Write
  some compile-time positive and negative tests to this effect).  The static asserts would certainly
  work.


Features necessary for "version 1.0"
- implementation of diagonal 2-tensors (of based vector spaces)
- implementation of the optimization for contraction with diagonal 2-tensors (necessary so 
  that we can implement inner products and other similar bilinear forms efficiently)
- refactoring the Eigen interop code to be strongly typed
- do more assembler code inspection for each of the compilers we use (GCC, Clang, MSVC) to
  make sure that it's generating code that's as efficient as we expect it to be (this is 
  really important)
- refactoring the unit tests to account for the strongly-typed refactor in general
- writing unit tests for the new code (general symmetric and antisymmetric N-tensors)
- possibly providing operator overloads to do non-indexed-expression vector/matrix math like
  Eigen does (so this library could be used by "laymen" without using abstract index notation)
- regularize/clean up the template code naming scheme
- generating documentation (Doxygen comments for the code, Doxygen-generated high-level
  documentation, and LaTeX writeups of the abstract math)
- translating LVD code (Victor's legacy metaprogramming lib) into "native Tensor Heaven" code
  (important for legal purposes)
- Talking to Tom about officially licensing the LVD unit test code (important for legal purposes)


Notes for [probable] upgrade to C++11 (to happen after "version 1.0" is reached)
- "Template typedefs" are possible through "alias declarations" in C++11:

    C++11 added alias declarations, which are generalization of typedef, allowing templates:

    template <size_t N>
    using Vector = Matrix<N, 1>;

    The type Vector<3> is equivalent to Matrix<3, 1>.
- All the TypeList_t stuff (which is deeply interwoven into Tensor Heaven) could be refactored
  to use variadic templates, though it would probably be good to do a bunch of experiments and
  gain experience using them before settling on a design/best practice.
- Tons of the metaprogramming uses static const variables -- these can be changed to use constexpr.
- Static asserts with error strings will be awesome (no more making enums for the error messages).
- Use nullptr
- Change private constructors to use the new " = delete" notation added in C++11.


Notes/Reflections on the development of a really really template-heavy math library
- The overarching conclusion is that C++ template metaprogramming (TMP) is the shittiest
  functional programming language that is widely used -- it's an emergent property of the original
  idea of making generic code (container classes, etc), and so was never designed as a first class
  language, and that really shows.  Doing things in C++ TMP which are quick and easy in a "real"
  functional language like Haskell require lots of extra red tape (e.g. all the extra uses of
  the "typename" and "template" keywords) and feel kludgey.  The error messages it produces are
  clearly tiny glimmers of the light of Hell leaking into our reality.
- Trying to have the compiler enforce the conceptual type system through the C++ type system
  is untenable, as it is too strict and the compile errors it produces are unreadable.
  * A good trick is to write template metafunctions with less constraint and then use explicit static
    asserts to enforce the conceptual type system.  Ted calls this a "honey bucket" for the compiler.
    For example, to enforce that only up/down index pairs can be contracted in a tensor expression,
    write the C++ template code to allow any pairs of indices to be contracted, and then use a
    static assert to enforce the up/down pairing, thereby controlling the situation when there
    is an index mismatch.  The error message produced is then readable and meaningful.
- Trying to encode the full, deep mathematical relationships in the C++ type system proved to be
  too difficult, because C++ ties its types to code.
  * The solution appears to be (though the full solution is yet to be implemented as of 2013.07.21)
    implementing the mathematical relationships in "pure" types (compile-time only, no code) in a
    "conceptual" layer, and put the implementations in its own layer.  This forces the designer
    not to mix up the two domains, and the division enhances clarity.
- Template code takes forever to compile in some cases.  This certainly happened in some of the
  Tensor Hell unit tests, where there the same templatized tests were being run on many types.
  * When possible and when it makes sense (such as in unit tests where there are many test cases),
    break code that uses templates up into many separate source files, so that parallel computation
    can be used to speed things along.
